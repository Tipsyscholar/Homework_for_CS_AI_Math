{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s(a):\n",
    "    a.append(5)\n",
    "a=[4,5,6]\n",
    "b=a\n",
    "s(a)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfec1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "a={4:5}\n",
    "print(a.get(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fabfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4, 5, 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set((4,5,6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6621af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9949aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "k=[a for a in range(5)]\n",
    "a\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09817848",
   "metadata": {},
   "outputs": [],
   "source": [
    "p= 'REPLACE_THIS_WITH_PASSPHRASE'\n",
    "hashlib.sha224(p.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e55fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go # 导入 plotly\n",
    "\n",
    "# --- 1. 加载和解析数据 ---\n",
    "# (这部分和之前的代码完全相同)\n",
    "file_path = '汇总2.xlsx' \n",
    "try:\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    \n",
    "    x_labels = df.iloc[1, 2:].values.astype(float)\n",
    "    y_labels = df.iloc[2:, 1].values.astype(float)\n",
    "    z_data = df.iloc[2:, 2:].values.astype(float)\n",
    "\n",
    "    X, Y = np.meshgrid(x_labels, y_labels)\n",
    "    \n",
    "    xs = X.flatten()\n",
    "    ys = Y.flatten()\n",
    "    zs = z_data.flatten()\n",
    "\n",
    "    # --- 2. 使用 Plotly 绘制 3D 散点图 ---\n",
    "\n",
    "    # 创建一个 3D 散点图对象\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=xs,  # X 轴数据\n",
    "        y=ys,  # Y 轴数据\n",
    "        z=zs,  # Z 轴数据\n",
    "        mode='markers', # 模式：只显示点\n",
    "        marker=dict(\n",
    "            size=5,                # 点的大小\n",
    "            color=zs,              # 点的颜色基于 Z 值\n",
    "            colorscale='Viridis',  # 使用 'Viridis' 色图 (和 matplotlib 一样)\n",
    "            opacity=0.8,           # 透明度\n",
    "            colorbar=dict(title='数值') # 添加颜色条\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    # --- 3. 设置图表布局 (标题和坐标轴标签) ---\n",
    "    fig.update_layout(\n",
    "        title='FLP 与 Raf 表达量 3D散点图',\n",
    "        scene=dict(\n",
    "            xaxis_title='FLP 表达量',\n",
    "            yaxis_title='Raf 表达量',\n",
    "            zaxis_title='数值'\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=40) # 调整边界\n",
    "    )\n",
    "\n",
    "    # --- 4. 显示图表 ---\n",
    "    # 这将在您的默认浏览器中打开一个可交互的 .html 文件\n",
    "    # 或者直接在 Jupyter Notebook 的输出单元格中显示\n",
    "    fig.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：未找到文件 '{file_path}'。\")\n",
    "except Exception as e:\n",
    "    print(f\"处理数据时发生错误：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "\n",
    "# --- 0. 开启 Matplotlib 交互模式 (重要！) ---\n",
    "# 如果您在 Jupyter/VS Code Notebook, 请在开头运行\n",
    "# %matplotlib widget \n",
    "# (需要先 pip install ipympl)\n",
    "\n",
    "# --- 1. 配置matplotlib以支持中文 ---\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei'] # Windows/Linux\n",
    "    plt.rcParams['axes.unicode_minus'] = False \n",
    "except Exception as e:\n",
    "    print(f\"警告：设置中文字体失败，标签可能无法正常显示。错误: {e}\")\n",
    "\n",
    "# --- 2. 加载和解析数据 ---\n",
    "file_path = '汇总2.xlsx' \n",
    "try:\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    \n",
    "    x_labels = df.iloc[1, 2:].values.astype(float)\n",
    "    y_labels = df.iloc[2:, 1].values.astype(float)\n",
    "    z_data = df.iloc[2:, 2:].values.astype(float)\n",
    "\n",
    "    X, Y = np.meshgrid(x_labels, y_labels)\n",
    "    \n",
    "    xs = X.flatten() # 展平为 1D 数组\n",
    "    ys = Y.flatten() # 展平为 1D 数组\n",
    "    zs = z_data.flatten() # 展平为 1D 数组\n",
    "\n",
    "    # --- 3. 准备训练数据 ---\n",
    "    # sklearn 需要的 X (特征) 是一个 (n_samples, n_features) 的2D数组\n",
    "    # 在这里是 (64, 2)\n",
    "    X_train = np.stack([xs, ys], axis=1)\n",
    "    # sklearn 需要的 y (目标) 是一个 (n_samples,) 的1D数组\n",
    "    y_train = zs\n",
    "\n",
    "    # --- 4. 训练回归决策树 ---\n",
    "    # 我们设置一个 max_depth (最大深度) 来防止树长得过深 (过拟合)\n",
    "    # 您可以调整 max_depth=4 这个值，比如改成 3 或 5 看看效果\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=7, random_state=42)\n",
    "    tree_reg.fit(X_train, y_train)\n",
    "\n",
    "    # --- 5. 【请求一】返回决策树架构 ---\n",
    "    print(\"--- 回归决策树架构 (Decision Tree Architecture) ---\")\n",
    "    feature_names = ['FLP 表达量', 'Raf 表达量']\n",
    "    tree_rules = export_text(tree_reg, feature_names=feature_names)\n",
    "    print(tree_rules)\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # --- 6. 【请求二】将其填充到空间中 (可视化) ---\n",
    "    \n",
    "    # a. 创建一个更精细的网格 (grid) 用于绘图\n",
    "    # 我们将在 x 和 y 的最小/最大值之间各取 100 个点\n",
    "    x_range = np.linspace(xs.min(), xs.max(), 100)\n",
    "    y_range = np.linspace(ys.min(), ys.max(), 100)\n",
    "    \n",
    "    # b. 创建绘图用的 X, Y 坐标网格\n",
    "    X_vis, Y_vis = np.meshgrid(x_range, y_range)\n",
    "    \n",
    "    # c. 准备用于预测的输入数据 (100*100 = 10000 个点)\n",
    "    # (10000, 2)\n",
    "    X_pred_input = np.stack([X_vis.flatten(), Y_vis.flatten()], axis=1)\n",
    "    \n",
    "    # d. 使用训练好的模型进行预测\n",
    "    Z_pred = tree_reg.predict(X_pred_input)\n",
    "    \n",
    "    # e. 将预测结果 Z_pred 变回 (100, 100) 的网格形状\n",
    "    Z_vis = Z_pred.reshape(X_vis.shape)\n",
    "\n",
    "    # --- 7. 绘制 3D 视图 ---\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # a. 绘制决策树预测的 \"曲面\" (会是阶梯状)\n",
    "    #    alpha=0.7 设置透明度，方便看到下面的点\n",
    "    ax.plot_surface(X_vis, Y_vis, Z_vis, cmap='viridis', alpha=0.7, \n",
    "                    rstride=1, cstride=1, edgecolor='none')\n",
    "\n",
    "    # b. 绘制原始的 64 个数据点 (用红色大点表示)\n",
    "    ax.scatter(xs, ys, zs, c='red', s=40, depthshade=True, label='原始数据点')\n",
    "\n",
    "    # --- 8. 设置图表属性 ---\n",
    "    ax.set_title(f'回归决策树 (max_depth={tree_reg.max_depth}) 拟合曲面', fontsize=18, pad=20)\n",
    "    ax.set_xlabel('FLP 表达量', fontsize=12, labelpad=15)\n",
    "    ax.set_ylabel('Raf 表达量', fontsize=12, labelpad=15)\n",
    "    ax.set_zlabel('预测数值', fontsize=12, labelpad=15)\n",
    "    ax.legend()\n",
    "\n",
    "    # 设置一个更合适的视角\n",
    "    ax.view_init(elev=20, azim=-120) \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：未找到文件 '{file_path}'。\")\n",
    "except Exception as e:\n",
    "    print(f\"处理数据时发生错误：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# --- 导入 scikit-learn 模块 ---\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- 0. 开启 Matplotlib 交互模式 (重要！) ---\n",
    "# 如果您在 Jupyter/VS Code Notebook, 请在开头运行\n",
    "# %matplotlib widget \n",
    "# (需要先 pip install ipympl)\n",
    "\n",
    "# --- 1. 配置matplotlib以支持中文 ---\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei'] # Windows/Linux\n",
    "    plt.rcParams['axes.unicode_minus'] = False \n",
    "except Exception as e:\n",
    "    print(f\"警告：设置中文字体失败，标签可能无法正常显示。错误: {e}\")\n",
    "\n",
    "# --- 2. 加载和解析数据 ---\n",
    "# 注意：使用您提供的特定索引\n",
    "file_path = '汇总2.xlsx' \n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "\n",
    "    # --- 2b. 稳健的数据提取 ---\n",
    "    # (这可以防止因表格外的空单元格导致NaN)\n",
    "    \n",
    "    # 提取 X 轴标签\n",
    "    x_labels_raw = df.iloc[1, 2:]\n",
    "    x_indices = x_labels_raw.notna()\n",
    "    x_labels = x_labels_raw[x_indices].values.astype(float)\n",
    "    \n",
    "    # 提取 Y 轴标签\n",
    "    y_labels_raw = df.iloc[2:, 1]\n",
    "    y_indices = y_labels_raw.notna()\n",
    "    y_labels = y_labels_raw[y_indices].values.astype(float)\n",
    "    \n",
    "    # 根据 X 和 Y 的有效索引，提取 Z 数据块\n",
    "    z_data = df.iloc[y_indices[y_indices].index, \n",
    "                     x_indices[x_indices].index].values.astype(float)\n",
    "\n",
    "    print(f\"数据加载成功: X轴 {len(x_labels)} 个点, Y轴 {len(y_labels)} 个点, Z数据 {z_data.shape}\")\n",
    "\n",
    "    # --- 3. 准备通用数据 ---\n",
    "    \n",
    "    # a. 创建网格并展平，用于训练\n",
    "    X_grid, Y_grid = np.meshgrid(x_labels, y_labels)\n",
    "    xs = X_grid.flatten() # 1D 数组\n",
    "    ys = Y_grid.flatten() # 1D 数组\n",
    "    zs = z_data.flatten() # 1D 数组\n",
    "\n",
    "    # (N, 2) 的特征矩阵\n",
    "    X_train = np.stack([xs, ys], axis=1)\n",
    "    # (N,) 的目标向量\n",
    "    y_train = zs\n",
    "\n",
    "    # b. 创建精细的可视化网格\n",
    "    x_range = np.linspace(xs.min(), xs.max(), 100)\n",
    "    y_range = np.linspace(ys.min(), ys.max(), 100)\n",
    "    X_vis, Y_vis = np.meshgrid(x_range, y_range)\n",
    "    # (10000, 2) 的预测输入\n",
    "    X_pred_input = np.stack([X_vis.flatten(), Y_vis.flatten()], axis=1)\n",
    "\n",
    "    # --- 4. 数据标准化 (SVR 和 GPR 需要) ---\n",
    "    # 我们分别缩放 X (特征) 和 y (目标)\n",
    "    scaler_X = StandardScaler().fit(X_train)\n",
    "    # y 需要是 (N, 1) 形状才能被缩放\n",
    "    scaler_y = StandardScaler().fit(y_train.reshape(-1, 1))\n",
    "\n",
    "    X_train_scaled = scaler_X.transform(X_train)\n",
    "    y_train_scaled = scaler_y.transform(y_train.reshape(-1, 1)).ravel() # .ravel() 变回 (N,)\n",
    "    \n",
    "    # 稍后我们也需要缩放可视化网格\n",
    "    X_pred_input_scaled = scaler_X.transform(X_pred_input)\n",
    "\n",
    "\n",
    "    # ==========================================================\n",
    "    # --- 模型 1: SVR (支持向量回归) ---\n",
    "    # ==========================================================\n",
    "    print(\"\\n正在训练 SVR...\")\n",
    "    # C: 惩罚参数。值越大，模型对训练数据拟合越紧。\n",
    "    # gamma: 'scale' 是一个好的默认值，定义了单个训练样本的影响范围\n",
    "    svr = SVR(kernel='rbf', C=20, gamma='auto')\n",
    "    svr.fit(X_train_scaled, y_train_scaled) # 使用标准化数据进行训练\n",
    "\n",
    "    # 预测 (在标准化的X上)\n",
    "    Z_pred_scaled = svr.predict(X_pred_input_scaled)\n",
    "    \n",
    "    # **关键**: 将预测结果 Z 反向转换回原始尺度\n",
    "    Z_pred_svr = scaler_y.inverse_transform(Z_pred_scaled.reshape(-1, 1))\n",
    "    \n",
    "    # 变回 100x100 网格\n",
    "    Z_vis_svr = Z_pred_svr.reshape(X_vis.shape)\n",
    "\n",
    "    # --- 绘制 SVR ---\n",
    "    fig1 = plt.figure(figsize=(14, 10))\n",
    "    ax1 = fig1.add_subplot(111, projection='3d')\n",
    "    ax1.plot_surface(X_vis, Y_vis, Z_vis_svr, cmap='viridis', alpha=0.8, \n",
    "                     rstride=1, cstride=1, edgecolor='none')\n",
    "    ax1.scatter(xs, ys, zs, c='red', s=40, depthshade=True, label='原始数据点')\n",
    "    ax1.set_title(f'SVR (RBF 核) 拟合曲面', fontsize=18, pad=20)\n",
    "    ax1.set_xlabel('X 轴 (FLP 表达量)', fontsize=12, labelpad=15)\n",
    "    ax1.set_ylabel('Y 轴 (Raf 表达量)', fontsize=12, labelpad=15)\n",
    "    ax1.set_zlabel('Z 轴 (预测数值)', fontsize=12, labelpad=15)\n",
    "    ax1.legend()\n",
    "    ax1.view_init(elev=20, azim=-120)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "    # --- 模型 2: GPR (高斯过程回归) - 调参平滑版 ---\n",
    "    # ==========================================================\n",
    "    print(\"\\n正在训练 GPR (调参平滑版)...\")\n",
    "    \n",
    "    # *** 关键调参 ***\n",
    "    # 我们将调大 RBF 的 'length_scale' (增加平滑度)\n",
    "    # 和 WhiteKernel 的 'noise_level' (降低对异常点的敏感度)\n",
    "\n",
    "    # 1. RBF: length_scale_bounds=(0.5, 1e3) \n",
    "    #    我们强制 length_scale (影响范围) 至少为 0.5 (在标准化空间中)\n",
    "    #    而不是之前的 1e-2 (0.01)，这会防止出现尖峰。\n",
    "    #    我们将初始猜测 length_scale 设为 5.0 来鼓励平滑。\n",
    "    rbf_kernel = 1.0 * RBF(length_scale=5.0, length_scale_bounds=(1.0, 1e3))\n",
    "    \n",
    "    # 2. WhiteKernel: noise_level_bounds=(0.1, 1e1)\n",
    "    #    我们强制 noise_level (噪声水平) 至少为 0.1。\n",
    "    #    这告诉模型 \"数据本身是有噪声的，你不需要完美穿过每一个点\"。\n",
    "    #    这会极大地平滑掉那些由异常点引起的峰值。\n",
    "    white_kernel = WhiteKernel(noise_level=0.5, noise_level_bounds=(0.2, 1e1))\n",
    "    \n",
    "    # 将两个核组合起来\n",
    "    kernel = rbf_kernel + white_kernel\n",
    "    \n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "    \n",
    "    # 训练 (使用标准化的 X 和 y)\n",
    "    gpr.fit(X_train_scaled, y_train_scaled) \n",
    "\n",
    "    # (可选) 打印优化后的内核参数，这很有用\n",
    "    print(f\"GPR 优化后的内核: {gpr.kernel_}\")\n",
    "\n",
    "    # 预测 (在标准化的X上)\n",
    "    Z_pred_gpr_scaled, Z_std_gpr_scaled = gpr.predict(X_pred_input_scaled, return_std=True)\n",
    "    \n",
    "    # 反向转换回原始尺度\n",
    "    Z_pred_gpr = scaler_y.inverse_transform(Z_pred_gpr_scaled.reshape(-1, 1))\n",
    "    \n",
    "    # 变回 100x100 网格\n",
    "    Z_vis_gpr = Z_pred_gpr.reshape(X_vis.shape)\n",
    "\n",
    "    # --- 绘制 GPR ---\n",
    "    fig2 = plt.figure(figsize=(14, 10))\n",
    "    ax2 = fig2.add_subplot(111, projection='3d')\n",
    "    ax2.plot_surface(X_vis, Y_vis, Z_vis_gpr, cmap='plasma', alpha=0.8, \n",
    "                     rstride=1, cstride=1, edgecolor='none')\n",
    "    ax2.scatter(xs, ys, zs, c='red', s=40, depthshade=True, label='原始数据点')\n",
    "    ax2.set_title(f'GPR (高斯过程) 拟合曲面 - 平滑调参版', fontsize=18, pad=20)\n",
    "    ax2.set_xlabel('X 轴 (FLP 表达量)', fontsize=12, labelpad=15)\n",
    "    ax2.set_ylabel('Y 轴 (Raf 表达量)', fontsize=12, labelpad=15)\n",
    "    ax2.set_zlabel('Z 轴 (预测数值)', fontsize=12, labelpad=15)\n",
    "    ax2.legend()\n",
    "    ax2.view_init(elev=20, azim=-120)\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：未找到文件 '{file_path}'。\")\n",
    "    print(\"请确保您的Excel文件与Python脚本在同一目录下。\")\n",
    "except Exception as e:\n",
    "    print(f\"处理数据或绘图时发生错误：{e}\")\n",
    "    print(\"请检查您的Excel文件格式是否与代码中的 'iloc' 索引匹配。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "import graphviz # 用于可视化公式树\n",
    "\n",
    "# --- 0. 开启 Matplotlib 交互模式 (重要！) ---\n",
    "# %matplotlib widget \n",
    "\n",
    "# --- 1. 配置matplotlib以支持中文 ---\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False \n",
    "except Exception as e:\n",
    "    print(f\"警告：设置中文字体失败，标签可能无法正常显示。错误: {e}\")\n",
    "\n",
    "# --- 2. 加载和解析数据 (使用您指定的索引) ---\n",
    "file_path = '汇总2.xlsx' \n",
    "try:\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "\n",
    "    x_labels_raw = df.iloc[1, 2:]\n",
    "    x_indices = x_labels_raw.notna()\n",
    "    x_labels = x_labels_raw[x_indices].values.astype(float)\n",
    "    \n",
    "    y_labels_raw = df.iloc[2:, 1]\n",
    "    y_indices = y_labels_raw.notna()\n",
    "    y_labels = y_labels_raw[y_indices].values.astype(float)\n",
    "    \n",
    "    z_data = df.iloc[y_indices[y_indices].index, \n",
    "                     x_indices[x_indices].index].values.astype(float)\n",
    "\n",
    "    print(f\"数据加载成功: X轴 {len(x_labels)} 个点, Y轴 {len(y_labels)} 个点, Z数据 {z_data.shape}\")\n",
    "\n",
    "    # --- 3. 准备训练数据 ---\n",
    "    X_grid, Y_grid = np.meshgrid(x_labels, y_labels)\n",
    "    xs = X_grid.flatten()\n",
    "    ys = Y_grid.flatten()\n",
    "    zs = z_data.flatten()\n",
    "\n",
    "    X_train = np.stack([xs, ys], axis=1) # (N, 2)\n",
    "    y_train = zs                         # (N,)\n",
    "    \n",
    "    # --- 4. 训练符号回归模型（优化参数以减少内存使用）---\n",
    "    print(\"\\n--- 正在运行符号回归 (Genetic Programming) ---\")\n",
    "    print(\"这可能需要几分钟，请稍候...\")\n",
    "    \n",
    "    # 配置\"数学积木\" - 减少复杂函数以降低计算负担\n",
    "    function_set = ['add', 'sub', 'mul', 'div', 'sqrt']  # 移除 sin, cos, log 以加速\n",
    "    \n",
    "    est_gp = SymbolicRegressor(\n",
    "        population_size=500,      # 从 2000 降到 500（减少内存）\n",
    "        generations=15,           # 从 30 降到 15（加速训练）\n",
    "        stopping_criteria=10,    \n",
    "        function_set=function_set,\n",
    "        metric='mean absolute error',\n",
    "        p_crossover=0.7,\n",
    "        p_subtree_mutation=0.1,\n",
    "        p_hoist_mutation=0.05,\n",
    "        p_point_mutation=0.1,\n",
    "        max_samples=0.9,\n",
    "        verbose=1,\n",
    "        n_jobs=4,                 # 从 -1 改为 4（限制并行数，避免过载）\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 终极猴子补丁 (HACK) V3.0 - 完全兼容版 ---\n",
    "    #\n",
    "    # 解释：gplearn 0.4.2 与 sklearn 1.7.2 有多个兼容性问题：\n",
    "    # 1. sklearn 1.7.2 删除了 _validate_data 方法\n",
    "    # 2. gplearn 的 predict 需要 n_features_in_ 属性\n",
    "    # 我们必须手动修复这两个问题\n",
    "    #\n",
    "    import types\n",
    "    from sklearn.utils.validation import check_X_y, check_array\n",
    "\n",
    "    # 修复 1: 定义 _validate_data 函数\n",
    "    def _our_own_validate_data(self, X, y=None, y_numeric=True, ensure_min_samples=2):\n",
    "        if y is not None:\n",
    "            # 训练时：检查 X 和 y\n",
    "            X_checked, y_checked = check_X_y(X, y, y_numeric=y_numeric, \n",
    "                                             ensure_min_samples=ensure_min_samples)\n",
    "            # 关键：设置 n_features_in_ 属性\n",
    "            self.n_features_in_ = X_checked.shape[1]\n",
    "            return X_checked, y_checked\n",
    "        else:\n",
    "            # 预测时：只检查 X\n",
    "            X_checked = check_array(X)\n",
    "            return X_checked\n",
    "\n",
    "    # 修复 2: 定义 _validate_params (sklearn 1.7.2 需要)\n",
    "    def _dummy_validate_params(self):\n",
    "        pass\n",
    "\n",
    "    # 3. 把这两个函数\"绑\"到 est_gp 实例上\n",
    "    est_gp._validate_data = types.MethodType(_our_own_validate_data, est_gp)\n",
    "    est_gp._validate_params = types.MethodType(_dummy_validate_params, est_gp)\n",
    "    #\n",
    "    # --- 补丁结束 ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    # 现在再运行 .fit()，所有兼容性问题都解决了\n",
    "    est_gp.fit(X_train, y_train)\n",
    "    \n",
    "    # --- 5. 【请求结果】打印找到的最佳公式 ---\n",
    "    print(\"\\n--- 符号回归完成 ---\")\n",
    "    print(\"找到的最佳公式 (Lisp 格式):\")\n",
    "    print(est_gp._program)\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    # --- 6. 将其填充到空间中 (可视化) - 降低分辨率以节省内存 ---\n",
    "    \n",
    "    # a. 创建可视化网格（从 100x100 降到 50x50，减少75%的点）\n",
    "    x_range = np.linspace(xs.min(), xs.max(), 50)  # 从 100 降到 50\n",
    "    y_range = np.linspace(ys.min(), ys.max(), 50)  # 从 100 降到 50\n",
    "    X_vis, Y_vis = np.meshgrid(x_range, y_range)\n",
    "    X_pred_input = np.stack([X_vis.flatten(), Y_vis.flatten()], axis=1)\n",
    "    \n",
    "    # b. 使用找到的公式进行预测\n",
    "    print(\"正在生成预测点...\")\n",
    "    Z_pred_gp = est_gp.predict(X_pred_input)\n",
    "    \n",
    "    # c. 展平预测结果用于绘制散点图\n",
    "    x_pred_flat = X_vis.flatten()\n",
    "    y_pred_flat = Y_vis.flatten()\n",
    "    z_pred_flat = Z_pred_gp.flatten()\n",
    "\n",
    "    # --- 7. 绘制 3D 散点图（仅数据点） ---\n",
    "    print(\"正在绘制图表...\")\n",
    "    fig = plt.figure(figsize=(12, 9))  # 从 (14, 10) 略微缩小\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # 绘制预测点（模型生成的空间点，用浅色小点）\n",
    "    ax.scatter(x_pred_flat, y_pred_flat, z_pred_flat, \n",
    "               c=z_pred_flat, cmap='coolwarm', s=8, alpha=0.4, \n",
    "               depthshade=True, label='模型预测点')\n",
    "    \n",
    "    # 绘制原始数据点（用黑色大点突出显示）\n",
    "    ax.scatter(xs, ys, zs, c='black', s=60, depthshade=True, \n",
    "               edgecolors='yellow', linewidths=1.5, label='原始数据点')\n",
    "    \n",
    "    ax.set_title(f'符号回归 3D散点图（仅数据点）', fontsize=16, pad=15)\n",
    "    ax.set_xlabel('X 轴 (FLP 表达量 - X0)', fontsize=11, labelpad=12)\n",
    "    ax.set_ylabel('Y 轴 (Raf 表达量 - X1)', fontsize=11, labelpad=12)\n",
    "    ax.set_zlabel('Z 轴 (预测数值)', fontsize=11, labelpad=12)\n",
    "    ax.legend()\n",
    "    ax.view_init(elev=20, azim=-120) \n",
    "    plt.show()\n",
    "    print(\"图表绘制完成！\")\n",
    "\n",
    "    # --- 8. (可选) 可视化公式树 ---\n",
    "    print(\"\\n正在生成公式树... (将保存为 'symbolic_formula.png')\")\n",
    "    try:\n",
    "        dot_data = est_gp._program.export_graphviz()\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        # 保存为文件。在 Notebook 中也可以直接输入 graph 变量来显示\n",
    "        graph.render('symbolic_formula', format='png', cleanup=True)\n",
    "        print(\"公式树已保存！\")\n",
    "    except Exception as e:\n",
    "        print(f\"无法生成公式树。请确保您已安装 Graphviz 可执行文件。错误: {e}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：未找到文件 '{file_path}'。\")\n",
    "except Exception as e:\n",
    "    print(f\"处理数据或绘图时发生错误：{e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()  # 打印详细错误信息以便调试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f31aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d05783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 配置中文显示\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "except:\n",
    "    pass\n",
    "\n",
    "file_path = '汇总2.xlsx'\n",
    "\n",
    "try:\n",
    "    # 读取数据\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    \n",
    "    x_labels_raw = df.iloc[1, 2:]\n",
    "    x_indices = x_labels_raw.notna()\n",
    "    x_labels = x_labels_raw[x_indices].values.astype(float)\n",
    "    \n",
    "    y_labels_raw = df.iloc[2:, 1]\n",
    "    y_indices = y_labels_raw.notna()\n",
    "    y_labels = y_labels_raw[y_indices].values.astype(float)\n",
    "    \n",
    "    z_data = df.iloc[y_indices[y_indices].index, \n",
    "                     x_indices[x_indices].index].values.astype(float)\n",
    "    \n",
    "    print(f\"数据加载: X轴 {len(x_labels)} 点, Y轴 {len(y_labels)} 点, Z数据 {z_data.shape}\")\n",
    "    \n",
    "    # 创建网格\n",
    "    X_grid, Y_grid = np.meshgrid(x_labels, y_labels)\n",
    "    xs = X_grid.flatten()\n",
    "    ys = Y_grid.flatten()\n",
    "    zs = z_data.flatten()\n",
    "    \n",
    "    # ========== 创建3D投影图 ==========\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # 主3D图\n",
    "    ax_3d = fig.add_subplot(2, 2, 1, projection='3d')\n",
    "    scatter = ax_3d.scatter(xs, ys, zs, c=zs, cmap='viridis', \n",
    "                            s=80, alpha=0.8, edgecolors='black', linewidths=1)\n",
    "    ax_3d.set_xlabel('FLP 表达量 (X)', fontsize=11, labelpad=10)\n",
    "    ax_3d.set_ylabel('Raf 表达量 (Y)', fontsize=11, labelpad=10)\n",
    "    ax_3d.set_zlabel('数值 (Z)', fontsize=11, labelpad=10)\n",
    "    ax_3d.set_title('3D 数据点分布', fontsize=14, pad=15)\n",
    "    ax_3d.view_init(elev=25, azim=-60)\n",
    "    plt.colorbar(scatter, ax=ax_3d, shrink=0.5, label='Z值')\n",
    "    \n",
    "    # X-Y投影 (俯视图)\n",
    "    ax_xy = fig.add_subplot(2, 2, 2)\n",
    "    scatter_xy = ax_xy.scatter(xs, ys, c=zs, cmap='viridis', \n",
    "                               s=100, alpha=0.7, edgecolors='black', linewidths=1)\n",
    "    ax_xy.set_xlabel('FLP 表达量 (X)', fontsize=11)\n",
    "    ax_xy.set_ylabel('Raf 表达量 (Y)', fontsize=11)\n",
    "    ax_xy.set_title('XY 平面投影 (俯视)', fontsize=12)\n",
    "    ax_xy.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter_xy, ax=ax_xy, label='Z值')\n",
    "    \n",
    "    # X-Z投影 (侧视图)\n",
    "    ax_xz = fig.add_subplot(2, 2, 3)\n",
    "    scatter_xz = ax_xz.scatter(xs, zs, c=zs, cmap='plasma', \n",
    "                               s=100, alpha=0.7, edgecolors='black', linewidths=1)\n",
    "    ax_xz.set_xlabel('FLP 表达量 (X)', fontsize=11)\n",
    "    ax_xz.set_ylabel('数值 (Z)', fontsize=11)\n",
    "    ax_xz.set_title('XZ 平面投影 (侧视)', fontsize=12)\n",
    "    ax_xz.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter_xz, ax=ax_xz, label='Z值')\n",
    "    \n",
    "    # Y-Z投影 (正视图)\n",
    "    ax_yz = fig.add_subplot(2, 2, 4)\n",
    "    scatter_yz = ax_yz.scatter(ys, zs, c=zs, cmap='coolwarm', \n",
    "                               s=100, alpha=0.7, edgecolors='black', linewidths=1)\n",
    "    ax_yz.set_xlabel('Raf 表达量 (Y)', fontsize=11)\n",
    "    ax_yz.set_ylabel('数值 (Z)', fontsize=11)\n",
    "    ax_yz.set_title('YZ 平面投影 (正视)', fontsize=12)\n",
    "    ax_yz.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter_yz, ax=ax_yz, label='Z值')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ 3D投影图绘制完成!\")\n",
    "    print(f\"  - 左上: 3D立体图\")\n",
    "    print(f\"  - 右上: XY平面投影 (俯视)\")\n",
    "    print(f\"  - 左下: XZ平面投影 (侧视)\")\n",
    "    print(f\"  - 右下: YZ平面投影 (正视)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 未找到文件 '{file_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f83e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function defaults b list ID: 2830221234560\n",
      "--------------------\n",
      "a is still None (Immutable)\n",
      "b list ID: 2830221234560\n",
      "b: [100]\n",
      "a is still None (Immutable)\n",
      "b list ID: 2830221234560\n",
      "b: [100, 100]\n",
      "a is still None (Immutable)\n",
      "b list ID: 2830221232512\n",
      "b: [100]\n",
      "a is still None (Immutable)\n",
      "b list ID: 2830221234560\n",
      "b: [100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "def func(a=None, b=[]):\n",
    "    if a is None:\n",
    "        print(f\"a is still None (Immutable)\")\n",
    "    else:\n",
    "        print(f\"a is now {a} (New local variable)\")\n",
    "    \n",
    "    b.append(100)\n",
    "    print(f\"b list ID: {id(b)}\")\n",
    "    print(f\"b: {b}\")\n",
    "\n",
    "print(f\"Function defaults b list ID: {id(func.__defaults__[1])}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# 第一次调用\n",
    "func()\n",
    "# b: [100]\n",
    "\n",
    "# 第二次调用（a 还是 None，b 却带着上次修改的值）\n",
    "func()\n",
    "# b: [100, 100] \n",
    "\n",
    "# 传入新的列表，b 的 ID 改变\n",
    "func(b=[])\n",
    "# b: [100] (这是新的列表)\n",
    "\n",
    "# 第三次调用（不传 b，b 再次使用那个共享的、被修改过的列表）\n",
    "func()\n",
    "# b: [100, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85202a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__builtins__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a400574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__builtins__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07a9f943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "class A():\n",
    "    k=[]\n",
    "    def l(self):\n",
    "        print(\"a\")\n",
    "    def __init__(self):\n",
    "        self.l()\n",
    "        self.k.append(1)\n",
    "\n",
    "a=A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1068ac07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[4,5]\n",
    "\n",
    "b=list(a)\n",
    "b.append(6)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db3e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[4,5,5,6,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "619911c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 5]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.remove(5)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fdb50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.insert(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d503a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好\n",
      "好的\n"
     ]
    }
   ],
   "source": [
    "f=open(\"try.txt\",'r',encoding=\"utf-8\")\n",
    "k=f.read()\n",
    "print(\"你好\\n好的\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64890358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 的梯度: tensor([2., 2.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. 原始张量 A，需要梯度\n",
    "A = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# 2. 原始运算，形成 A 的历史\n",
    "B = A * 2 \n",
    "# B 继承了 A 的历史，B.grad_fn 存在\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 目标：创建一个 C，保留 B 的历史，但 C 之后的计算是新的分支\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# **方法一：使用 .clone()**\n",
    "# 默认情况下，.clone() 会继承 requires_grad=True\n",
    "C = B.clone()\n",
    "\n",
    "# C 现在是计算图上的一个新节点，但它依赖于 B (通过 clone 操作)\n",
    "# C.grad_fn 存在，指向 CloneBackward\n",
    "# C 的数据是 B 的副本\n",
    "\n",
    "# 3. 在 C 上进行后续运算（分叉）\n",
    "D = C + 5\n",
    "# D 依赖于 C。当计算 D 的梯度时，它会通过 C 回传到 B，再回传到 A。\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 验证：执行反向传播\n",
    "D_sum = D.sum()\n",
    "D_sum.backward()\n",
    "\n",
    "# 验证结果：\n",
    "print(f\"A 的梯度: {A.grad}\") # A 应该有梯度，因为历史被保留了\n",
    "# A 的梯度: tensor([1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc39303c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([2.0, 3.0])\n",
    "A=B*2\n",
    "B.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "182af5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0==0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1afbd39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 8)ok(1, 4),好啊('什么', 88)\n"
     ]
    }
   ],
   "source": [
    "print(\"{1}ok{0},好啊{2}\".format(*{1:4,5:8,\"什么\":88}.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b437dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "async def F():\n",
    "    print(\"hello\")\n",
    "\n",
    "await F()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67912664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in iter(range(10)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b667cbd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "not writable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m dict_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgold\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[0;32m      7\u001b[0m dict_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minventory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshield\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\Torch\\lib\\json\\__init__.py:180\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m--> 180\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mUnsupportedOperation\u001b[0m: not writable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dict_json={}\n",
    "with open(\"try.json\",'r',encoding='utf-8')  as f:\n",
    "    dict_json=json.load(f)\n",
    "    dict_json['level']+=1\n",
    "    dict_json['gold']+=50\n",
    "    dict_json['inventory'].append(\"shield\")\n",
    "    json.dump(dict_json,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffc7a510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "sum_all=0\n",
    "with open(\"try.csv\",'r',encoding=\"utf-8\") as f:\n",
    "    a=csv.DictReader(f)\n",
    "    for row in a:\n",
    "        sum_all+=int(row['Price'])*int(row['Count'])\n",
    "\n",
    "sum_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34acebb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple, 10\\nbanana, 5\\norange, 8\\ngrape, 20\\napple, 5'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"try.txt\",'r+',encoding='utf-8') as f:\n",
    "    a=f.read()\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebda11a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': 1}\n",
      "{'apple': 1, 'banana': 1}\n",
      "{'apple': 1, 'banana': 1, 'orange': 1}\n",
      "{'apple': 1, 'banana': 1, 'orange': 1, 'grape': 1}\n",
      "{'apple': 2, 'banana': 1, 'orange': 1, 'grape': 1}\n"
     ]
    }
   ],
   "source": [
    "with open(\"try.txt\",'r',encoding='utf-8') as f:\n",
    "    a=f.readline()\n",
    "    fruit={}\n",
    "    while(a!=''):\n",
    "        a=a.strip().lower().split(\",\")[0]\n",
    "        if a not in fruit.keys():\n",
    "            fruit[a]=1\n",
    "        else:\n",
    "            fruit[a]+=1\n",
    "        print(fruit)\n",
    "        a=f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64a4bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple, 10\n",
      "banana, 5\n",
      "orange, 8\n",
      "grape, 20\n",
      "apple, 5\n"
     ]
    }
   ],
   "source": [
    "with open(\"try.txt\",'r',encoding='utf-8') as f:\n",
    "    a=f.readline()\n",
    "    while(a!=''):\n",
    "        a=a.strip().lower()\n",
    "        print(a)\n",
    "        a=f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aef5d214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试文件已生成。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 生成一些假文件\n",
    "files = [\"exp1.txt\", \"exp2.txt\", \"config.json\", \"data.csv\", \"log.txt\", \"model.json\"]\n",
    "for f_name in files:\n",
    "    with open(f_name, 'w') as f:\n",
    "        f.write(\"dummy content\")\n",
    "print(\"测试文件已生成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fdde9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"text_data\"):\n",
    "    os.mkdir(\"text_data\")\n",
    "if not os.path.exists(\"json_data\"):\n",
    "    os.mkdir(\"json_data\")\n",
    "\n",
    "list_dir=os.listdir()\n",
    "for i,j in zip(list_dir,map(lambda x:os.path.splitext(x)[1],list_dir)):\n",
    "    if j=='.txt':\n",
    "        os.rename(i,os.path.join(\"text_data\",i))\n",
    "    if j=='.json':\n",
    "        os.rename(i,os.path.join(\"json_data\",i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "44efed09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copytree(\"text_data\",\"what\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8700b069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'build\\\\CMakeFiles'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname('build\\\\CMakeFiles\\\\TargetDirectories.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f76a2738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('user\\\\data', 'wat')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.split(os.path.splitext(\"user\\data\\wat.jpg\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c450238f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([[4,5,5,6],[5,6,5,8],[4,8,9,5]])\n",
    "a[a>5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68c76652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello,   worlg'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hello,   worlg\\n\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "428dd47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Link:\n",
    "    \"\"\"A linked list.\n",
    "\n",
    "    >>> s = Link(1)\n",
    "    >>> s.first\n",
    "    1\n",
    "    >>> s.rest is Link.empty\n",
    "    True\n",
    "    >>> s = Link(2, Link(3, Link(4)))\n",
    "    >>> s.first = 5\n",
    "    >>> s.rest.first = 6\n",
    "    >>> s.rest.rest = Link.empty\n",
    "    >>> s                                    # Displays the contents of repr(s)\n",
    "    Link(5, Link(6))\n",
    "    >>> s.rest = Link(7, Link(Link(8, Link(9))))\n",
    "    >>> s\n",
    "    Link(5, Link(7, Link(Link(8, Link(9)))))\n",
    "    >>> print(s)                             # Prints str(s)\n",
    "    <5 7 <8 9>>\n",
    "    \"\"\"\n",
    "    empty = ()\n",
    "    def __init__(self, first, rest=empty):\n",
    "        assert rest is Link.empty or isinstance(rest, Link)\n",
    "        self.first = first\n",
    "        self.rest = rest\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.rest is not Link.empty:\n",
    "            rest_repr = ', ' + repr(self.rest)\n",
    "        else:\n",
    "            rest_repr = ''\n",
    "        return 'Link(' + repr(self.first) + rest_repr + ')'\n",
    "\n",
    "    def __str__(self):\n",
    "        string = '<'\n",
    "        while self.rest is not Link.empty:\n",
    "            string += str(self.first) + ' '\n",
    "            self = self.rest\n",
    "        return string + str(self.first) + '>'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fe998dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45, 4, 65, 5]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[45,4,65,5]\n",
    "a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "35559836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45, 4, 65, 5]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "copy.deepcopy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "98f20aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=Link(2)\n",
    "s=Link(1,b)\n",
    "a=copy.deepcopy(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b88d56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Tree:\n",
    "    \"\"\"A tree has a label and a list of branches.\n",
    "\n",
    "    >>> t = Tree(3, [Tree(2, [Tree(5)]), Tree(4)])\n",
    "    >>> t.label\n",
    "    3\n",
    "    >>> t.branches[0].label\n",
    "    2\n",
    "    >>> t.branches[1].is_leaf()\n",
    "    True\n",
    "    \"\"\"\n",
    "    def __init__(self, label, branches=[]):\n",
    "        self.label = label\n",
    "        for branch in branches:\n",
    "            assert isinstance(branch, Tree)\n",
    "        self.branches = list(branches)\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return not self.branches\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.branches:\n",
    "            branch_str = ', ' + repr(self.branches)\n",
    "        else:\n",
    "            branch_str = ''\n",
    "        return 'Tree({0}{1})'.format(repr(self.label), branch_str)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join(self.indented())\n",
    "\n",
    "    def indented(self):\n",
    "        lines = []\n",
    "        for b in self.branches:\n",
    "            for line in b.indented():\n",
    "                lines.append('  ' + line)\n",
    "        return [str(self.label)] + lines\n",
    "    \n",
    "t=Tree(0)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1002c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=1\n",
    "def f():\n",
    "    a=index\n",
    "f()\n",
    "index\n",
    "f.__closure__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac21e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "542a4701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=1\n",
    "def f():\n",
    "    def g():\n",
    "        global index\n",
    "        index+=1\n",
    "        return index\n",
    "    return g\n",
    "f()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce735aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def make_counter():\n",
    "    # 使用一个列表作为容器，存储计数值\n",
    "    count_container = [0] \n",
    "    \n",
    "    def increment():\n",
    "        # 我们没有重新赋值 count_container，只是修改了它指向的列表的内容\n",
    "        count_container[0] += 1\n",
    "        return count_container[0]\n",
    "        \n",
    "    return increment\n",
    "\n",
    "counter = make_counter()\n",
    "\n",
    "print(counter()) # 输出: 1\n",
    "print(counter()) # 输出: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1da9647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=(4 ,5 ,6)\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a1c4312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, [5, 6, 6]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[4 ,5 ,[5, 6 ]]\n",
    "b=a[2]\n",
    "c=a[:]\n",
    "b.append(6)\n",
    "c.append(6)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054dcad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "class nil:\n",
    "    alll=2\n",
    "    def g():\n",
    "        print(\"hello\")\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.alll=3\n",
    "\n",
    "a=nil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b647e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.first=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9683241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "j=10\n",
    "value_and_prob_j={}\n",
    "for k in range(2*j,6*j+1):\n",
    "    N=0\n",
    "    for n in range((k-2*j)//5+1):\n",
    "        N+=(-1)**n*scipy.special.comb(j,n)*scipy.special.comb(k-j-5*n-1,j-1)\n",
    "    value_and_prob_j[k]=N/(5**j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e3ce8f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aparagraphaboutdogs']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_input='A paragraph about dogs.'\n",
    "new=''.join(c for c in string_input if c.isalpha())\n",
    "new=new.lower().split(' ')\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b953ace5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 2}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={}\n",
    "a[1+1]=2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39ceab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f4643e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"'\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5d5c827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'s\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typed=\"s'\"\n",
    "temp=typed[1]+typed[0]+typed[2:]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa0fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(range(10))\n",
    "for i in a.copy():\n",
    "    a.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b4d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileProcessingError(Exception):\n",
    "    def __init__(self, message, filename, lineno):\n",
    "        super().__init__(message) # 调用父类构造函数设置主要的错误信息\n",
    "        self.filename = filename\n",
    "        self.lineno = lineno\n",
    "\n",
    "# 抛出时：\n",
    "try:\n",
    "    FileProcessingError(\"文件格式错误\", \"data.txt\", 15)\n",
    "except FileProcessingError(\"文件格式错误\", \"data.txt\", 15) as e:\n",
    "    print(e.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6c04f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piii(length=2):\n",
    "    \n",
    "    piii.num-=1\n",
    "    pass\n",
    "piii.num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff074fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m {a:\u001b[38;5;241m1\u001b[39m}\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "{a:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5905ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n"
     ]
    }
   ],
   "source": [
    "print('\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "57577af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(*args,k=1):\n",
    "    num=0\n",
    "    for i in args:\n",
    "        num+=i\n",
    "    return num\n",
    "f(*([4,5,6]+[4,5,6]),k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af578bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avsve'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice([\"ac\",\"asc\",\"avsve\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "714ca0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=lambda self,game :  None\n",
    "g(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba1275",
   "metadata": {},
   "source": [
    "Correction Speed: 915.4297033615109 wpm\n",
    "Correctly Corrected: 440 words\n",
    "Incorrectly Corrected: 196 words\n",
    "Uncorrected: 51 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5b6de",
   "metadata": {},
   "source": [
    "Correction Speed: 1245.1672966717474 wpm\n",
    "Correctly Corrected: 578 words\n",
    "Incorrectly Corrected: 286 words\n",
    "Uncorrected: 70 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa26ac",
   "metadata": {},
   "source": [
    "Correction Speed: 505.5774036685697 wpm\n",
    "Correctly Corrected: 265 words\n",
    "Incorrectly Corrected: 97 words\n",
    "Uncorrected: 21 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4379a",
   "metadata": {},
   "source": [
    "Correction Speed: 691.6608272363577 wpm\n",
    "Correctly Corrected: 333 words\n",
    "Incorrectly Corrected: 148 words\n",
    "Uncorrected: 41 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf1454",
   "metadata": {},
   "source": [
    "Correction Speed: 92704.22414664713 wpm\n",
    "Correctly Corrected: 428 words\n",
    "Incorrectly Corrected: 400 words\n",
    "Uncorrected: 112 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a977c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804a6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'range(0, 10)'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "165b1931",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtry.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m f\n",
      "File \u001b[1;32mc:\\Users\\18239\\miniconda3\\envs\\py_analysis_env\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\18239\\miniconda3\\envs\\py_analysis_env\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\18239\\miniconda3\\envs\\py_analysis_env\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 1)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for file in open(\"try.json\"):\n",
    "    f=json.loads(file)\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5fa624f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fact(n,result):\n",
    "    def tunk():\n",
    "        if n==0:\n",
    "            return result\n",
    "        return fact(n-1,result*n)\n",
    "    return tunk\n",
    "\n",
    "\n",
    "def fact_finla(n):\n",
    "    val=fact(n,1)\n",
    "    while(callable(val)):\n",
    "        val=val()\n",
    "    return val\n",
    "\n",
    "fact_finla(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "846dfca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callable(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
